{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anotações e Entendimento Geral do Paper Pix2Pix GAN:\n",
    "A arquitetura da rede Pix2Pix original proposta é um modelo de redes adversárias generativas (GANs) voltado para tarefas de tradução de imagem para imagem. Ela consiste em dois componentes principais: o Gerador (Generator) e o Discriminador (Discriminator).\n",
    "\n",
    "### Gerador (Generator):\n",
    "O gerador utiliza uma arquitetura de encoder-decoder com skip connections, semelhante à U-Net.\n",
    " - Encoder: c64-c128-c256-c512-c512-c512-c512-c512\n",
    " - Decoder: cd512-cd512-cd512-c512-c256-c128-c64\n",
    "\n",
    "### Discriminador (Discriminator):\n",
    "O discriminador utiliza uma arquitetura chamada PatchGAN. Em vez de classificar a imagem inteira como real ou falsa, ele divide a imagem em patches menores e faz a classificação em cada um desses patches.\n",
    "- Arquitetura: c64-c128-c256-c512\n",
    "- Camada Final: aplica uma convolução que transforma o mapa de ativação em uma dimensão (1D), seguida por uma função sigmoid para produzir a probabilidade de autenticidade.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desenvolvimento do Código:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import ones\n",
    "from numpy import zeros\n",
    "from numpy.random import randint\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.utils import plot_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando os Dados e Criando Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente a ideia eh utilizar o mesmo dataset do paper e depois testar em algum dos outros datases propostos para esse trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nao deu certo ainda :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (<string>, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<string>:34\u001b[0;36m\u001b[0m\n\u001b[0;31m    model = Model([in_src_img, in_target_img], patch_out)\u001b[0m\n\u001b[0m                                                         ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "# fazendo o modelo em si\n",
    "\n",
    "def Descriminador(img_shape):\n",
    "    init = RandomNormal(stddev=0.02) # como feito no paper\n",
    "\n",
    "    in_src_img = Input(shape=img_shape)\n",
    "    in_target_img = Input(shape=img_shape)\n",
    "\n",
    "    merged_img = Concatenate()[in_src_img, in_target_img]\n",
    "\n",
    "    # arquitetura da rede em si:\n",
    "    layer = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged_img)\n",
    "    layer = LeakyReLU(alpha=0.2)(layer)\n",
    "    # C128\n",
    "    layer = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = LeakyReLU(alpha=0.2)(layer)\n",
    "    # C256\n",
    "    layer = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = LeakyReLU(alpha=0.2)(layer)\n",
    "    # C512\n",
    "    layer = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = LeakyReLU(alpha=0.2)(layer)\n",
    "    # second last output layer\n",
    "    layer = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(layer)\n",
    "    layer = BatchNormalization()(layer)\n",
    "    layer = LeakyReLU(alpha=0.2)(layer)\n",
    "    # patch output\n",
    "    layer = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(layer)\n",
    "    patch_out = Activation('sigmoid')(layer)\n",
    "\n",
    "    # define model\n",
    "\tmodel = Model([in_src_img, in_target_img], patch_out)\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "    \n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
